{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03a5e4a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-02T01:18:27.072784Z",
     "start_time": "2022-01-02T01:18:26.659627Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/y/opt/anaconda3/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "from urllib.parse import quote\n",
    "from tqdm import tqdm, trange\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from IPython.display import clear_output\n",
    "import os,os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eaa19d08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-02T01:19:26.127043Z",
     "start_time": "2022-01-02T01:19:26.066907Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_todate():\n",
    "    return date.today()\n",
    "\n",
    "def selenium_get_Code_104(url):\n",
    "    chrome_options = Options() # 啟動無頭模式\n",
    "    chrome_options.add_argument('--headless')  #規避google bug\n",
    "    chrome_options.add_argument('--disable-gpu')\n",
    "    driver = webdriver.Chrome(executable_path = /Users/y/Desktop/gitHub/learning/chromedriver)\n",
    "    driver.get(url)\n",
    "    save = driver.page_source\n",
    "    driver.quit()#關閉瀏覽器\n",
    "    soup = BeautifulSoup(save, \"html.parser\")\n",
    "    page = soup.select('.page-select.js-paging-select.gtm-paging-top')[0].find_all('option')[-1].get('value')\n",
    "    return page\n",
    "\n",
    "def read_url(url):\n",
    "    USER_AGENT_LIST = [\n",
    "        \"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; AcooBrowser; .NET CLR 1.1.4322; .NET CLR 2.0.50727)\",\n",
    "        \"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0; Acoo Browser; SLCC1; .NET CLR 2.0.50727; Media Center PC 5.0; .NET CLR 3.0.04506)\",\n",
    "        \"Mozilla/4.0 (compatible; MSIE 7.0; AOL 9.5; AOLBuild 4337.35; Windows NT 5.1; .NET CLR 1.1.4322; .NET CLR 2.0.50727)\",\n",
    "        \"Mozilla/5.0 (Windows; U; MSIE 9.0; Windows NT 9.0; en-US)\",\n",
    "        \"Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 2.0.50727; Media Center PC 6.0)\",\n",
    "        \"Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 1.0.3705; .NET CLR 1.1.4322)\",\n",
    "        \"Mozilla/4.0 (compatible; MSIE 7.0b; Windows NT 5.2; .NET CLR 1.1.4322; .NET CLR 2.0.50727; InfoPath.2; .NET CLR 3.0.04506.30)\",\n",
    "        \"Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN) AppleWebKit/523.15 (KHTML, like Gecko, Safari/419.3) Arora/0.3 (Change: 287 c9dfb30)\",\n",
    "        \"Mozilla/5.0 (X11; U; Linux; en-US) AppleWebKit/527+ (KHTML, like Gecko, Safari/419.3) Arora/0.6\",\n",
    "        \"Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.2pre) Gecko/20070215 K-Ninja/2.1.1\",\n",
    "        \"Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN; rv:1.9) Gecko/20080705 Firefox/3.0 Kapiko/3.0\",\n",
    "        \"Mozilla/5.0 (X11; Linux i686; U;) Gecko/20070322 Kazehakase/0.4.5\",\n",
    "        \"Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.8) Gecko Fedora/1.9.0.8-1.fc10 Kazehakase/0.5.6\",\n",
    "        \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/535.11\",\n",
    "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_3) AppleWebKit/535.20 (KHTML, like Gecko) Chrome/19.0.1036.7 Safari/535.20\",\n",
    "        \"Opera/9.80 (Macintosh; Intel Mac OS X 10.6.8; U; fr) Presto/2.9.168 Version/11.52\",\n",
    "        \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.11 (KHTML, like Gecko) Chrome/20.0.1132.11 TaoBrowser/2.0 Safari/536.11\",\n",
    "        \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1180.71 Safari/537.1 LBBROWSER\",\n",
    "        \"Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E; LBBROWSER)\",\n",
    "        \"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; QQDownload 732; .NET4.0C; .NET4.0E; LBBROWSER)\",\n",
    "        \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.84 Safari/535.11 LBBROWSER\",\n",
    "        \"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E)\",\n",
    "        \"Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E; QQBrowser/7.0.3698.400)\",\n",
    "        \"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; QQDownload 732; .NET4.0C; .NET4.0E)\",\n",
    "        \"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Trident/4.0; SV1; QQDownload 732; .NET4.0C; .NET4.0E; 360SE)\",\n",
    "        \"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; QQDownload 732; .NET4.0C; .NET4.0E)\",\n",
    "        \"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E)\",\n",
    "        \"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1180.89 Safari/537.1\",\n",
    "        \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1180.89 Safari/537.1\",\n",
    "        \"Mozilla/5.0 (iPad; U; CPU OS 4_2_1 like Mac OS X; zh-cn) AppleWebKit/533.17.9 (KHTML, like Gecko) Version/5.0.2 Mobile/8C148 Safari/6533.18.5\",\n",
    "        \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:2.0b13pre) Gecko/20110307 Firefox/4.0b13pre\",\n",
    "        \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:16.0) Gecko/20100101 Firefox/16.0\",\n",
    "        \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11\",\n",
    "        \"Mozilla/5.0 (X11; U; Linux x86_64; zh-CN; rv:1.9.2.10) Gecko/20100922 Ubuntu/10.10 (maverick) Firefox/3.6.10\",\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\",\n",
    "        ]\n",
    "    USER_AGENT = random.choice(USER_AGENT_LIST)\n",
    "    headers = {'user-agent': USER_AGENT}\n",
    "    s = requests.Session()\n",
    "    req = s.get(url, headers = headers)\n",
    "    soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "    return soup\n",
    "\n",
    "def csv_column_104(path_csv, key_txt): #建立行標題\n",
    "    with open(path_csv + '.csv', mode='a+', newline='', encoding='utf-8') as employee_file: \n",
    "        employee_writer = csv.writer(employee_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        employee_writer.writerow(['日期', '工作名稱', '公司名稱', '公司地址', '薪資', '工作內容', '地區', '經歷', '學歷', '公司人數', '文章編號', '工作網址'])\n",
    "\n",
    "def find_title_104(key_txt):\n",
    "    #路徑組合\n",
    "    today = get_todate()\n",
    "    path_csv = \"%s\" % os.getcwd() + '\\\\' + 'jobs_csv\\\\'+ str(today) + key_txt + '_104人力銀行'\n",
    "    if not os.path.isdir('jobs_csv'): # 確認是否有jobs_csv資料夾  沒有則返回Ture\n",
    "        os.mkdir('jobs_csv') # 建立jobs_csv資料夾\n",
    "        print('建立jobs_csv資料夾完成')\n",
    "    csv_column_104(path_csv, key_txt) #建立行標題\n",
    "    csv_save = \"\"\n",
    "    key = quote(key_txt)\n",
    "    #  104 api searchTempExclude=2  -> 設定排除派遣\n",
    "    find_page_url = 'https://www.104.com.tw/jobs/search/?ro=0&kwop=7&keyword={0}&order=15&asc=0&page=1&mode=s&jobsource=2018indexpoc&searchTempExclude=2'.format(key)\n",
    "    get_sum_page = int(selenium_get_Code_104(find_page_url))\n",
    "    print('共有：' + str(get_sum_page) + ' 頁')\n",
    "    for i in tqdm(range(1, get_sum_page+1)):  #set page 1 to find all max page ,tqdm讀取進度條\n",
    "        url = 'https://www.104.com.tw/jobs/search/?ro=0&kwop=7&keyword={0}&order=15&asc=0&page={1}&mode=s&jobsource=2018indexpoc&searchTempExclude=2'.format(key, i) \n",
    "        #time.sleep(random.randint(2,10)) #隨機等待\n",
    "        soup = read_url(url) #讀取網頁\n",
    "        print('目前爬取頁面是：' + url)\n",
    "        for title_1 in soup.select('.b-block__left'):\n",
    "            #有三個資料是無資料的，遇到無資料就跳過這個迴圈\n",
    "            if title_1.select('.b-list-inline.b-clearfix.job-list-item__company') != soup.select('.b-block__left')[0].select('.b-list-inline.b-clearfix.job-list-item__company'):\n",
    "                #日期\n",
    "                try:\n",
    "                    #正常代表找到 讚 廣告 (業主買廣告)，發生異常代表找不到 讚，執行except找日期 \n",
    "                    date_match__ = title_1.select('.b-icon--gray.b-icon--w18')[0].select('use')[0]\n",
    "                    date = '廣告'\n",
    "                except:\n",
    "                    date = title_1.select('.b-tit__date')[0].get_text().replace('\\n','').replace(' ','')\n",
    "        \n",
    "                #地區\n",
    "                area = title_1.select('.b-list-inline.b-clearfix.job-list-intro.b-content')[0].find('li').get_text()\n",
    "                #經歷(年資)\n",
    "                experience = title_1.select('.b-list-inline.b-clearfix.job-list-intro.b-content')[0].find_all('li')[1].get_text()\n",
    "                try: #業者沒有輸入學歷，遇到錯誤處理\n",
    "                    #學歷\n",
    "                    education = title_1.select('.b-list-inline.b-clearfix.job-list-intro.b-content')[0].find_all('li')[2].get_text()\n",
    "                except:\n",
    "                    education = \"\"\n",
    "                #工作網址\n",
    "                title_url = title_1.select('.js-job-link')[0].get('href')[2:]\n",
    "                #get 文章編號\n",
    "                title_str = title_url.split('?')[0].split('/')[-1] #get 文章編號\n",
    "                #標題名稱\n",
    "                title = title_1.select('.js-job-link')[0].get_text() #get title\n",
    "                #print(title + title_url + area)\n",
    "                #公司名\n",
    "                company_name = title_1.select('li')[1].find('a').get('title').split('\\n')[0][4:]\n",
    "                try:\n",
    "                    #公司地址\n",
    "                    company_address = title_1.select('li')[1].find('a').get('title').split('\\n')[1][5:]\n",
    "                except:\n",
    "                    company_address = \"\"\n",
    "                try:\n",
    "                    #簡介\n",
    "                    introduction = title_1.select('.job-list-item__info.b-clearfix.b-content')[0].get_text()\n",
    "                    #處理string \\r \\n5 \\n轉成''\n",
    "                    introduction = introduction.replace('\\r','').replace('\\n5','').replace('\\n','')\n",
    "                except:\n",
    "                    introduction = \"\"\n",
    "                #薪資\n",
    "                try:\n",
    "                    salary = title_1.select('.b-tag--default')[0].get_text()\n",
    "                except:\n",
    "                    salary = 0 #沒有寫薪資或待遇面議，設定 0\n",
    "                    \n",
    "                if salary == '待遇面議':\n",
    "                    salary = \"待遇面議\"\n",
    "                else: #數字處理 25000~35000 取25000最低薪資為主要，三位數 = 日薪，四位數 = 論件計酬\n",
    "                    try:\n",
    "                        salary = re.search('\\d+.\\d+', salary).group()\n",
    "                    except:\n",
    "                        salary = 0\n",
    "                #員工人數\n",
    "                try:\n",
    "                    people = title_1.select('.b-tag--default')[1].get_text()\n",
    "                except:\n",
    "                    people = \"\"\n",
    "                #clear_output() # 清除輸出 用於清除進度讀，註解#不使用：用來檢查出錯的網址\n",
    "\n",
    "                with open(path_csv + '.csv', mode='a+', newline='', encoding='utf-8') as employee_file: #w\n",
    "                    employee_writer = csv.writer(employee_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                    employee_writer.writerow([date, title, company_name, company_address, salary, introduction, area, experience, education, people, title_str, title_url])\n",
    "            else:\n",
    "                continue\n",
    "    return print('爬取104完成：請開啟csv檔案')\n",
    "\n",
    "\n",
    "# input_go = input('輸入關鍵字')\n",
    "# save_title_data = find_title_104(input_go)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############ 1111人力銀行 #########\n",
    "\n",
    "\n",
    "def selenium_get_Code_1111(url):\n",
    "    chrome_options = Options() # 啟動無頭模式\n",
    "    chrome_options.add_argument('--headless')  #規避google bug\n",
    "    chrome_options.add_argument('--disable-gpu')\n",
    "    driver = webdriver.Chrome(chrome_options=chrome_options)\n",
    "    driver.get(url)\n",
    "    save = driver.page_source\n",
    "    driver.quit()#關閉瀏覽器\n",
    "    soup = BeautifulSoup(save, \"html.parser\")\n",
    "    \n",
    "    page = soup.select('.custom-select')[0].select('option')[0].text\n",
    "    page = page.split('/')\n",
    "    page = page[1].strip(' ')\n",
    "    return page\n",
    "\n",
    "\n",
    "def csv_column_1111(path_csv): #建立行標題\n",
    "    with open(path_csv + '.csv', mode='a+', newline='', encoding='utf-8') as employee_file: \n",
    "        employee_writer = csv.writer(employee_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        employee_writer.writerow(['日期', '工作名稱', '公司名稱', '公司地址', '薪資', '工作內容', '地區', '經歷', '學歷', '工作網址'])\n",
    "\n",
    "def find_data_1111(soup):\n",
    "    #錢錢\n",
    "    mnone = soup.select('.needs') \n",
    "    #縣市區域\n",
    "    location = soup.select('.needs')\n",
    "    #日期\n",
    "    get_date = soup.select('.date')\n",
    "    #簡介\n",
    "    jbInfoTxt = soup.select('.jbInfoTxt')\n",
    "    #網址\n",
    "    jobs_url = soup.select('.position0')\n",
    "    #公司名稱、類別、住址\n",
    "    company_data = soup.select('.d-md-flex')\n",
    "    #工作標題\n",
    "    title = soup.select('.position0')\n",
    "    #工作經驗\n",
    "    jobs_exp = soup.select('.needs')\n",
    "    # 學歷\n",
    "    education = soup.select('.needs')\n",
    "    return mnone, location, jbInfoTxt, jobs_url, company_data, title, jobs_exp, get_date, education\n",
    "\n",
    "        \n",
    "def find_title_1111(key_txt):\n",
    "    #路徑組合\n",
    "    today = get_todate()\n",
    "    path_csv = \"%s\" % os.getcwd() + '\\\\' + 'jobs_csv\\\\' + str(today) + key_txt + '_1111人力銀行'\n",
    "    if not os.path.isdir('jobs_csv'): # 確認是否有jobs_csv資料夾  沒有則返回Ture\n",
    "        os.mkdir('jobs_csv') # 建立jobs_csv資料夾\n",
    "        print('建立jobs_csv資料夾完成')\n",
    "    csv_column_1111(path_csv) #建立行標題\n",
    "    key = quote(key_txt)\n",
    "    find_page_url = 'https://www.1111.com.tw/job-bank/job-index.asp?si=1&ss=s&ks={0}&page=1'.format(key)\n",
    "    #取得最大page數\n",
    "    get_sum_page = int(selenium_get_Code_1111(find_page_url))\n",
    "    print('共有：' + str(get_sum_page) + ' 頁')\n",
    "    \n",
    "    for i in tqdm(range(1, get_sum_page+1)):\n",
    "        url = 'https://www.1111.com.tw/job-bank/job-index.asp?si=1&ss=s&ks={0}&page={1}'.format(key, i)\n",
    "        soup = read_url(url) #讀取網頁\n",
    "        #讀取網頁資料\n",
    "        mnone, location, jbInfoTxt, jobs_url, company_data, title, jobs_exp, get_date, education = find_data_1111(soup)\n",
    "        print('目前爬取頁面是：' + url)\n",
    "        for mnone, location, jbInfoTxt, jobs_url, company_data, title, jobs_exp, get_date, education in zip(mnone, location, jbInfoTxt, jobs_url, company_data, title, jobs_exp, get_date, education):\n",
    "            #錢 取最低薪資\n",
    "            try:\n",
    "                mnone = mnone.find_all(\"span\")[1].get_text()\n",
    "                get_mone = re.search('\\d+.\\d+', mnone).group()\n",
    "            except:\n",
    "                get_mone = '面議（經常性薪資4萬/月含以上）' #也可以直接給40000\n",
    "            #日期\n",
    "            get_date = get_date.get_text()[5:]\n",
    "\n",
    "            #縣市區域\n",
    "            location = location.find_all(\"span\")[0].get_text()\n",
    "\n",
    "            #簡介\n",
    "            jbInfoTxt = jbInfoTxt.get_text().replace(\"\\xa0\", \"\") #刪除\\xa0\n",
    "\n",
    "            #工作網址\n",
    "            jobs_url = 'https://www.1111.com.tw{0}'.format(jobs_url.find('a').get('href'))\n",
    "\n",
    "            #公司名\n",
    "            company = company_data.find_all('a')[0].get('title').replace('\\r','').split('\\n')[0][6:]\n",
    "\n",
    "            #公司分類 目前暫不使用\n",
    "            category = company_data.find_all('a')[0].get('title').replace('\\r','').split('\\n')[1][6:]\n",
    "\n",
    "            #公司地址\n",
    "            address = company_data.find_all('a')[0].get('title').replace('\\r','').split('\\n')[2][6:]\n",
    "\n",
    "            #工作標題\n",
    "            title = title.find('a').get('title')\n",
    "\n",
    "            # 工作經驗\n",
    "            jobs_exp = jobs_exp.find_all(\"span\")[2].get_text()\n",
    "\n",
    "            # 學歷\n",
    "            education = education.find_all(\"span\")[3].get_text()\n",
    "            # 儲存\n",
    "\n",
    "            # clear_output() # 清除輸出 用於清除進度讀\n",
    "\n",
    "            with open(path_csv + '.csv', mode='a+', newline='', encoding='utf-8') as employee_file: #w\n",
    "                employee_writer = csv.writer(employee_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                employee_writer.writerow([get_date, title, company, address, get_mone, jbInfoTxt, location, jobs_exp, education, jobs_url])\n",
    "    return print('爬取1111完成：請開啟csv檔案')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8a8d2fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-02T01:19:57.728426Z",
     "start_time": "2022-01-02T01:19:57.673892Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/y/opt/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: use options instead of chrome_options\n",
      "  \n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: 'chromedriver' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/py36/lib/python3.6/site-packages/selenium/webdriver/common/service.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m                                             \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                                             stdin=PIPE)\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py36/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[1;32m    728\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    730\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py36/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1363\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1365\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'chromedriver': 'chromedriver'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-f2ee0a59bafb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfind_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfind_title_104\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfind_title_1111\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-f7b0661b04cc>\u001b[0m in \u001b[0;36mfind_title_104\u001b[0;34m(key_txt)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m#  104 api searchTempExclude=2  -> 設定排除派遣\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mfind_page_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://www.104.com.tw/jobs/search/?ro=0&kwop=7&keyword={0}&order=15&asc=0&page=1&mode=s&jobsource=2018indexpoc&searchTempExclude=2'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mget_sum_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselenium_get_Code_104\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind_page_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'共有：'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_sum_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' 頁'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_sum_page\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m#set page 1 to find all max page ,tqdm讀取進度條\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-f7b0661b04cc>\u001b[0m in \u001b[0;36mselenium_get_Code_104\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mchrome_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--headless'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#規避google bug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mchrome_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--disable-gpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchrome_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchrome_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msave\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py36/lib/python3.6/site-packages/selenium/webdriver/chrome/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, keep_alive)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mservice_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mservice_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             log_path=service_log_path)\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py36/lib/python3.6/site-packages/selenium/webdriver/common/service.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 raise WebDriverException(\n\u001b[1;32m     82\u001b[0m                     \"'%s' executable needs to be in PATH. %s\" % (\n\u001b[0;32m---> 83\u001b[0;31m                         os.path.basename(self.path), self.start_error_message)\n\u001b[0m\u001b[1;32m     84\u001b[0m                 )\n\u001b[1;32m     85\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEACCES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebDriverException\u001b[0m: Message: 'chromedriver' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home\n"
     ]
    }
   ],
   "source": [
    "find_key = 'python'\n",
    "find_title_104(find_key)\n",
    "find_title_1111(find_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfc6ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
